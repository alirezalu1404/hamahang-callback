import requests, json, time, datetime

DATA_FILE = "ads_log.json"
CHECK_INTERVAL = 900  # 15 Ø¯Ù‚ÛŒÙ‚Ù‡ (Ù‚Ø§Ø¨Ù„ ØªØºÛŒÛŒØ± ØªÙˆØ³Ø· Ù…Ø¯ÛŒØ± Ø§ÙØ²ÙˆÙ†Ù‡)

def fetch_ads(search_url):
    try:
        r = requests.get(search_url, timeout=10)
        if r.status_code != 200:
            return []
        # Ø¯Ø± Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² HTML Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
        links = [f"{search_url}?ad={i}" for i in range(5)]
        return links
    except Exception as e:
        print("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§:", e)
        return []

def save_to_json(links):
    ts = datetime.datetime.now().isoformat()
    record = {"timestamp": ts, "ads": links}
    try:
        with open(DATA_FILE, "a", encoding="utf-8") as f:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
        print(f"âœ… {len(links)} Ø¢Ú¯Ù‡ÛŒ Ø¯Ø± Ø²Ù…Ø§Ù† {ts} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    except Exception as e:
        print("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ:", e)

if __name__ == "__main__":
    search_url = input("ğŸ”¹ Ù„ÛŒÙ†Ú© Ù†Ø´Ø§Ù† Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: ").strip()
    while True:
        ads = fetch_ads(search_url)
        if ads:
            save_to_json(ads)
        time.sleep(CHECK_INTERVAL)
